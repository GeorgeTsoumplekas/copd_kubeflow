{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from source.expert_knowledge import check_expert_knowledge\n",
    "from source.statistical_analysis import check_statistical_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real_path = \"data/copd.csv\"\n",
    "data_real = pd.read_csv(data_real_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_knowledge_results = check_expert_knowledge(data_real)\n",
    "expert_knowledge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_analysis_results = check_statistical_analysis(data_real, data_real_path)\n",
    "statistical_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synthetic_path = \"data/copd_synthetic.csv\"\n",
    "data_synthetic = pd.read_csv(data_synthetic_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_knowledge_results = check_expert_knowledge(data_synthetic)\n",
    "expert_knowledge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_analysis_results = check_statistical_analysis(data_synthetic, data_synthetic_path)\n",
    "statistical_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_232840/2065486513.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../models/catboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_extra_target_col(data):\n",
    "    if \"copd\" in data.columns.tolist():\n",
    "        return data.drop(columns=[\"copd\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(X_train, X_test):\n",
    "    scale_features = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15]\n",
    "    cat_features = [13]\n",
    "\n",
    "    transformers = [\n",
    "        (\"one_hot\", OneHotEncoder(), cat_features),\n",
    "        (\"scale\", MinMaxScaler(), scale_features),\n",
    "    ]\n",
    "    col_transform = ColumnTransformer(\n",
    "        transformers=transformers, remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "    pipeline = Pipeline(steps=[(\"imp\", imputer), (\"preproc\", col_transform)])\n",
    "\n",
    "    X_train_proc = pipeline.fit_transform(X_train)\n",
    "    X_test_proc = pipeline.transform(X_test)\n",
    "\n",
    "    return X_train_proc, X_test_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_targets(y_train, y_test):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_proc = label_encoder.fit_transform(y_train)\n",
    "    y_test_proc = label_encoder.transform(y_test)\n",
    "\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    return y_train_proc, y_test_proc, label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_copd(data_path, test_size=0.3):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    data = check_extra_target_col(data)\n",
    "\n",
    "    X = data.loc[:, data.columns != \"COPDSEVERITY\"]\n",
    "    y = data[\"COPDSEVERITY\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    X_train_proc, X_test_proc = transform_features(X_train, X_test)\n",
    "\n",
    "    y_train_proc, y_test_proc, label_mapping = transform_targets(y_train, y_test)\n",
    "\n",
    "    return X_train_proc, X_test_proc, y_train_proc, y_test_proc, label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real, X_test_real, y_train_real, y_test_real, label_mapping_real = preprocess_copd(\"../data/copd.csv\", test_size=0.3)\n",
    "X_train_synthetic, X_test_synthetic, y_train_synthetic, y_test_synthetic, label_mapping_synthetic = preprocess_copd(\"../data/copd_synthetic.csv\", test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_real_pred = model.predict(X_test_real).reshape((-1, 1))\n",
    "y_test_synthetic_pred = model.predict(X_test_synthetic).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_report_real = classification_report(y_test_real, y_test_real_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsoump/post_market/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tsoump/post_market/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tsoump/post_market/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "cls_report_synthetic = classification_report(y_test_synthetic, y_test_synthetic_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in label_mapping_real.items():\n",
    "    cls_report_real[key] = cls_report_real.pop(str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in label_mapping_synthetic.items():\n",
    "    cls_report_synthetic[key] = cls_report_synthetic.pop(str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_evaluation_results = {\n",
    "    'real': cls_report_real,\n",
    "    'synthetic': cls_report_synthetic\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'real': {'accuracy': 0.8709677419354839,\n",
       "  'macro avg': {'precision': 0.675,\n",
       "   'recall': 0.71875,\n",
       "   'f1-score': 0.6944444444444444,\n",
       "   'support': 31.0},\n",
       "  'weighted avg': {'precision': 0.8258064516129032,\n",
       "   'recall': 0.8709677419354839,\n",
       "   'f1-score': 0.8458781362007168,\n",
       "   'support': 31.0},\n",
       "  'MILD': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 7.0},\n",
       "  'MODERATE': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 13.0},\n",
       "  'SEVERE': {'precision': 0.7,\n",
       "   'recall': 0.875,\n",
       "   'f1-score': 0.7777777777777778,\n",
       "   'support': 8.0},\n",
       "  'VERY SEVERE': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 3.0}},\n",
       " 'synthetic': {'accuracy': 0.5806451612903226,\n",
       "  'macro avg': {'precision': 0.5281862745098039,\n",
       "   'recall': 0.5096153846153846,\n",
       "   'f1-score': 0.47974358974358977,\n",
       "   'support': 31.0},\n",
       "  'weighted avg': {'precision': 0.5273561037318153,\n",
       "   'recall': 0.5806451612903226,\n",
       "   'f1-score': 0.521852770885029,\n",
       "   'support': 31.0},\n",
       "  'MILD': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5.0},\n",
       "  'MODERATE': {'precision': 0.5833333333333334,\n",
       "   'recall': 0.5384615384615384,\n",
       "   'f1-score': 0.56,\n",
       "   'support': 13.0},\n",
       "  'SEVERE': {'precision': 0.5294117647058824,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.6923076923076923,\n",
       "   'support': 9.0},\n",
       "  'VERY SEVERE': {'precision': 1.0,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.6666666666666666,\n",
       "   'support': 4.0}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
